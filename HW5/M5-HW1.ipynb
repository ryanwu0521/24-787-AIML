{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 (30 points)\n",
    "\n",
    "## Problem Description\n",
    "In this problem you will train decision tree and random forest models using sklearn on a real world dataset. The dataset is the *Cylinder Bands Data Set* from the UCI Machine Learning Repository: [https://archive.ics.uci.edu/ml/datasets/Cylinder+Bands](https://archive.ics.uci.edu/ml/datasets/Cylinder+Bands). The dataset is generated from rotogravure printers, with 39 unique features, and a binary classification label for each sample. The class is either 0, for 'band' or 1 for 'no band', where banding is an undesirable process delay that arises during the rotogravure printing process. By training ML models on this dataset, you could help identify or predict cases where these process delays are avoidable, thereby improving the efficiency of the printing. For the sake of this exercise, we only consider features 21-39 in the above link, and have removed any samples with missing values in that range. No further processing of the data is required on your behalf. The data has been partitioned into a training and testing set using an 80/20 split. Your models will be trained on just the test set, and accuracy results will be reported on both the training and testing sets.\n",
    "\n",
    "Fill out the notebook as instructed, making the requested plots and printing necessary values. \n",
    "\n",
    "*You are welcome to use any of the code provided in the lecture activities.*\n",
    "\n",
    "#### Summary of deliverables:\n",
    "\n",
    "- Accuracy function\n",
    "- Report accuracy of the DT model on the training and testing set\n",
    "- Report accuracy of the Random Forest model on the training and testing set\n",
    "\n",
    "#### Imports and Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Use the `np.load()` function to load \"w5-hw1-train.npy\" (training data) and \"w5-hw1-test.npy\" (testing data). The first 19 columns of each are the features. The last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# load the data\n",
    "training_data = np.load(\"data/w5-hw1-train.npy\")\n",
    "testing_data = np.load(\"data/w5-hw1-test.npy\")\n",
    "\n",
    "# split the data into features and labels\n",
    "X_train, y_train = training_data[:, :19], training_data[:, -1]\n",
    "X_test, y_test = testing_data[:, :19], testing_data[:, -1]\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write an accuracy function\n",
    "\n",
    "Write a function `accuracy(pred,label)` that takes in the models prediction, and returns the percentage of predictions that match the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "def accuracy(pred, label):\n",
    "    accuracy = np.sum(pred == label) / len(label) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a decision tree model\n",
    "\n",
    "Train a decision tree using `DecisionTreeClassifier()` with a `max_depth` of 10 and using a `random_state` of 0 to ensure repeatable results. Print the accuracy of the model on both the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of decision tree model:  93.12714776632302 %\n",
      "Testing accuracy of decision tree model:  65.75342465753424 %\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# train decision tree classifier\n",
    "dt = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred_train = dt.predict(X_train)\n",
    "dt_pred_test = dt.predict(X_test)\n",
    "\n",
    "dt_accuracy_training = accuracy(dt_pred_train, y_train)\n",
    "dt_accuracy_testing = accuracy(dt_pred_test, y_test)\n",
    "\n",
    "# print the accuracies\n",
    "print(\"Training accuracy of decision tree model: \", dt_accuracy_training,\"%\")\n",
    "print(\"Testing accuracy of decision tree model: \", dt_accuracy_testing,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a random forest model\n",
    "\n",
    "Train a random forest model using `RandomForestClassifier()` with a `max_depth` of 10, a `n_estimators` of 100, and using a random state of `0` to ensure repeatable results. Print the accuracy of the model on both the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of random forest model:  100.0 %\n",
      "Testing accuracy of random forest model:  82.1917808219178 %\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# train forst model\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=100, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred_train = rf.predict(X_train)\n",
    "rf_pred_test = rf.predict(X_test)\n",
    "rf_accuracy_training = accuracy(rf_pred_train, y_train)\n",
    "rf_accuracy_testing = accuracy(rf_pred_test, y_test)\n",
    "\n",
    "# print the accuracies\n",
    "print(\"Training accuracy of random forest model: \", rf_accuracy_training,\"%\")\n",
    "print(\"Testing accuracy of random forest model: \", rf_accuracy_testing,\"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss the performance of the models\n",
    "\n",
    "Compare the training and testing accuracy of the two models, and explain why the random forest model is advantageous compared to a standard decision tree model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training accuracy, the random forest model (100%) has a higher accuracy compared to the decision tree model (93.13%). For testing accuracy, the random forest model (82.19%) also has a higher accuracy compared to the decision tree model (65.75%). The random forest model is more advantageous compared to a standard decision tree model because of its ability to reduce overfitting and generalize better to unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
